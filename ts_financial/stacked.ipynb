{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from kagglegym import make\n",
    "import kagglegym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import linear_model, ensemble\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A custom function to compute the R score\n",
    "def get_reward(y_true, y_fit):\n",
    "    R2 = 1 - np.sum((y_true - y_fit)**2) / np.sum((y_true - np.mean(y_true))**2)\n",
    "    R = np.sign(R2) * math.sqrt(abs(R2))\n",
    "    return(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, model, columns):\n",
    "\n",
    "        self.model   = model\n",
    "        self.columns = columns\n",
    "        \n",
    "    def train_with_validation(self, train, validation):\n",
    "        # Get the X, and y values, \n",
    "        X_train = train[self.columns]\n",
    "        y_train = np.array(train.y)\n",
    "        X_val = validation[self.columns]\n",
    "        y_val = np.array(validation.y)\n",
    "        \n",
    "        self.model.fit(X_train, y_train)\n",
    "        reward = get_reward(y_val, self.model.predict(X_val))\n",
    "        score = self.model.score(X_val, y_val)\n",
    "        \n",
    "        print \"{} validation: {} score: {}\".format(\n",
    "            str(self.model).split('(')[0], \n",
    "            \"{0:.8f}\".format(reward),\n",
    "            \"{0:.8f}\".format(score))\n",
    "        \n",
    "    def train(self, train):\n",
    "        X_train = train[self.columns]\n",
    "        y_train = np.array(train.y)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        score = self.model.score(X_train, y_train)\n",
    "#         print \"{} trained successfully with score: {}\".format(\n",
    "#             str(self.model).split('(')[0], \n",
    "#             \"{0:.8f}\".format(score))\n",
    "    \n",
    "    def predict(self, features):   \n",
    "        return self.model.predict(features[self.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Stacked():\n",
    "    def __init__(self):\n",
    "        self.stacked_model = None\n",
    "        self.cv_xgb = None\n",
    "\n",
    "        self.model_dict = {}\n",
    "        \n",
    "        ENcolumns = ['technical_30', 'technical_20', 'technical_40',  ]\n",
    "        self.model_dict['elasticNet'] = Model(linear_model.ElasticNetCV(normalize=True), ENcolumns)\n",
    "        \n",
    "        Rcolumns = [ 'fundamental_52', 'technical_30', 'technical_33', 'technical_20']\n",
    "        self.model_dict['ridge'] = Model(linear_model.Ridge(normalize=True), Rcolumns)\n",
    "        \n",
    "        Lcolumns = ['fundamental_11', 'fundamental_12', 'technical_44' ]\n",
    "        self.model_dict['lasso'] = Model(linear_model.Lasso(normalize=True), Lcolumns)\n",
    "        \n",
    "#         Tcolumns = ['fundamental_53', 'technical_3' ,'technical_30']\n",
    "#         self.model_dict['tree'] = Model(xgb.XGBRegressor(), Tcolumns)\n",
    "        \n",
    "        Icolumns = ['fundamental_20', 'technical_13','technical_20' ,'technical_30']\n",
    "        self.model_dict['linear'] = Model(linear_model.LinearRegression(normalize=True), Icolumns)\n",
    "        \n",
    "        #self.columns = ['elasticNet', 'ridge', 'lasso', 'tree']\n",
    "        self.columns = ['elasticNet', 'ridge', 'linear', 'lasso']\n",
    "        \n",
    "    def train_with_validation(self, raw_train, train_split=700):\n",
    "        # split train and validation sets\n",
    "        X_train = raw_train[raw_train['timestamp'] < train_split]\n",
    "        val = raw_train[raw_train['timestamp'] > train_split]\n",
    "        X_val = val.drop('y', 1)\n",
    "        y_val = np.array(val.y)\n",
    "        \n",
    "        self.train(X_train)\n",
    "        val_preds = self.predict(X_val)\n",
    "\n",
    "        print \"Validation reward: {}\".format(get_reward(y_val, val_preds))    \n",
    "        \n",
    "         \n",
    "    def train(self, raw_train, train_split=500):\n",
    "        train = raw_train[raw_train['timestamp'] < train_split]\n",
    "        val = raw_train[raw_train['timestamp'] > train_split]\n",
    "        train = raw_train\n",
    "        for model in self.model_dict.values():\n",
    "            model.train(train)\n",
    "               \n",
    "        # train layer 1\n",
    "        l1_features = pd.DataFrame()\n",
    "        \n",
    "        for name, model in self.model_dict.iteritems():\n",
    "            if name in self.columns:\n",
    "                l1_features[name] = model.predict(train.drop('y', 1))   \n",
    "        l1_features['y'] = train.y.values\n",
    "        l1_features = l1_features.fillna(0)\n",
    "        print l1_features.shape\n",
    "        self.stacked_model = Model(linear_model.Ridge(alpha=.0001), self.columns)\n",
    "        self.stacked_model.train(l1_features)\n",
    "#         dmat = xgb.DMatrix(train.drop('y', 1), train.y)\n",
    "#         params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "#                      'objective': 'reg:linear', 'max_depth':6, 'min_child_weight':1}\n",
    "#         self.cv_xgb = xgb.cv(params = params, dtrain = dmat, num_boost_round = 3000, nfold = 5,\n",
    "#                 metrics = ['error'], # Make sure you enter metrics inside a list or you may encounter issues!\n",
    "#                 early_stopping_rounds = 100) # Look for early stopping that minimizes error\\\n",
    "        #final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "        print \"Stacked model successfully trained.\"\n",
    "            \n",
    "        \n",
    "    def predict(self, features):\n",
    "        assert self.stacked_model is not None, 'Model has not trained yet.'\n",
    "        l1_features = pd.DataFrame()\n",
    "        for name, model in self.model_dict.iteritems():\n",
    "            if name in self.columns:\n",
    "                l1_features[name] = model.predict(features)\n",
    "        preds = self.stacked_model.predict(l1_features)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize kaggle gym environment\n",
    "env = make()\n",
    "o = env.reset()\n",
    "raw_train = o.train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "averages_by_ts = raw_train.groupby('timestamp').aggregate(np.mean)\n",
    "offset_averages = averages_by_ts.shift(1)\n",
    "added_features = averages_by_ts.join(offset_averages, how='inner', rsuffix='_offset')\n",
    "raw_train = raw_train.join(added_features, on='timestamp', how='left', rsuffix='_rolling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(806298,)\n"
     ]
    }
   ],
   "source": [
    "print raw_train['technical_42_rolling'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(806298, 5)\n",
      "Stacked model successfully trained.\n"
     ]
    }
   ],
   "source": [
    "# stacked_val = Stacked()\n",
    "# stacked_val.train_with_validation(raw_train)\n",
    "# stacked= stacked_val\n",
    "stacked = Stacked()\n",
    "stacked.train(raw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dmat = xgb.DMatrix(l1_features, train.y)\n",
    "# params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "#              'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1}\n",
    "# booster = xgb.train(params = params, dtrain = dmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new calculation for score\n",
      "Starting to fit a model\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "0.0163421951821\n"
     ]
    }
   ],
   "source": [
    "env = make()\n",
    "o = env.reset()\n",
    "print('Starting a new calculation for score')\n",
    "rewards = []\n",
    "\n",
    "print('Starting to fit a model')\n",
    "while True:\n",
    "    features = o.features.copy().fillna(0)\n",
    "#     averages_by_ts = features[['technical_42', 'technical_12', 'timestamp']].groupby('timestamp').aggregate(np.mean)\n",
    "#     features = features.join(averages_by_ts, on='timestamp', how='left', rsuffix = '_rolling')\n",
    "    prediction  = stacked.predict(features)\n",
    "    target      = o.target\n",
    "    target['y'] = prediction\n",
    "\n",
    "    timestamp = o.features[\"timestamp\"][0]\n",
    "\n",
    "    if timestamp % 100 == 0 :\n",
    "        print timestamp\n",
    "    \n",
    "    o, reward, done, info = env.step(target)\n",
    "    rewards.append(reward)\n",
    "    if done: break\n",
    "\n",
    "print info['public_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_train = raw_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# columns_to_test = ['technical_20', 'technical_20_rolling', 'technical_20_offset', \n",
    "#                    'technical_30', 'technical_30_rolling', 'technical_30_offset',\n",
    "#                    'technical_40', 'technical_40_rolling', 'technical_40_offset',\n",
    "#                    'fundamental_11', 'fundamental_11_rolling', 'fundamental_11_offset']\n",
    "\n",
    "columns_to_test = ['technical_22', 'technical_20', 'technical_30', 'technical_13', \n",
    "    'technical_34', 'fundamental_11', 'technical_40', 'technical_19', 'technical_11', \n",
    "                  'technical_7', 'fundamental_53', 'fundamental_51']\n",
    "models = {}\n",
    "for i in range(len(columns_to_test)):\n",
    "    for j in range(i+1, len(columns_to_test)):\n",
    "        \n",
    "        m = Model(linear_model.LinearRegression(normalize=True), [columns_to_test[i], columns_to_test[j]])\n",
    "        m.train(raw_train)\n",
    "        models[columns_to_test[i] + '_' +  columns_to_test[j]]= m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8b4f882a9840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "print max(models, key=models.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new calculation for score\n",
      "Starting to fit a model\n",
      "column:-0.0110238809088\n",
      "Starting a new calculation for score\n",
      "Starting to fit a model\n",
      "column:-0.0750978618279\n",
      "Starting a new calculation for score\n",
      "Starting to fit a model\n",
      "column:-0.0848172390404\n",
      "Starting a new calculation for score\n",
      "Starting to fit a model\n",
      "column:-0.0172011256038\n",
      "Starting a new calculation for score\n",
      "Starting to fit a model\n",
      "column:-0.0950112445907\n",
      "Starting a new calculation for score\n",
      "Starting to fit a model\n",
      "column:-0.0874539856616\n",
      "Starting a new calculation for score\n",
      "Starting to fit a model\n",
      "column:-0.00861636034261\n",
      "Starting a new calculation for score\n",
      "Starting to fit a model\n",
      "column:-0.0353368838057\n",
      "Starting a new calculation for score\n",
      "Starting to fit a model\n",
      "column:-0.0882262871807\n",
      "Starting a new calculation for score\n",
      "Starting to fit a model\n",
      "column:-0.0106844739705\n",
      "Starting a new calculation for score\n",
      "Starting to fit a model\n",
      "column:-0.0605628374869\n",
      "Starting a new calculation for score\n",
      "Starting to fit a model\n",
      "column:-0.0868091008894\n"
     ]
    }
   ],
   "source": [
    "raw_columns = ['technical_20', 'technical_30', 'technical_40', 'fundamental_11']\n",
    "\n",
    "for model in models:\n",
    "    counter = 0\n",
    "    env = make()\n",
    "    o = env.reset()\n",
    "    print('Starting a new calculation for score')\n",
    "    rewards = []\n",
    "    \n",
    "    print('Starting to fit a model')\n",
    "    while True:\n",
    "        features = o.features.copy().fillna(method='ffill')\n",
    "        averages_by_ts = features[raw_columns +  ['timestamp']].groupby('timestamp').aggregate(np.mean)\n",
    "        averages_by_ts = averages_by_ts.join(averages_by_ts.shift(1),  how='inner', rsuffix='_offset')\n",
    "        features = features.join(averages_by_ts, on='timestamp', how='left', rsuffix = '_rolling')\n",
    "        prediction  = model.predict(features)\n",
    "        target      = o.target\n",
    "        target['y'] = prediction\n",
    "\n",
    "        timestamp = o.features[\"timestamp\"][0]\n",
    "\n",
    "        o, reward, done, info = env.step(target)\n",
    "        rewards.append(reward)\n",
    "        if done: break\n",
    "    counter += 1\n",
    "    print 'column:' + str(info['public_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
