{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8921483 rows of TRAIN.CSV!\n"
     ]
    }
   ],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import pandas as pd, numpy as np, os, gc\n",
    "\n",
    "# LOAD AND FREQUENCY-ENCODE\n",
    "FE = ['EngineVersion','AppVersion','AvSigVersion','Census_OSVersion']\n",
    "# LOAD AND ONE-HOT-ENCODE\n",
    "OHE = [ 'RtpStateBitfield','IsSxsPassiveMode','DefaultBrowsersIdentifier',\n",
    "        'AVProductStatesIdentifier','AVProductsInstalled', 'AVProductsEnabled',\n",
    "        'CountryIdentifier', 'CityIdentifier', \n",
    "        'GeoNameIdentifier', 'LocaleEnglishNameIdentifier',\n",
    "        'Processor', 'OsBuild', 'OsSuite',\n",
    "        'SmartScreen','Census_MDC2FormFactor',\n",
    "        'Census_OEMNameIdentifier', \n",
    "        'Census_ProcessorCoreCount',\n",
    "        'Census_ProcessorModelIdentifier', \n",
    "        'Census_PrimaryDiskTotalCapacity', 'Census_PrimaryDiskTypeName',\n",
    "        'Census_HasOpticalDiskDrive',\n",
    "        'Census_TotalPhysicalRAM', 'Census_ChassisTypeName',\n",
    "        'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n",
    "        'Census_InternalPrimaryDisplayResolutionHorizontal',\n",
    "        'Census_InternalPrimaryDisplayResolutionVertical',\n",
    "        'Census_PowerPlatformRoleName', 'Census_InternalBatteryType',\n",
    "        'Census_InternalBatteryNumberOfCharges',\n",
    "        'Census_OSEdition', 'Census_OSInstallLanguageIdentifier',\n",
    "        'Census_GenuineStateName','Census_ActivationChannel',\n",
    "        'Census_FirmwareManufacturerIdentifier',\n",
    "        'Census_IsTouchEnabled', 'Census_IsPenCapable',\n",
    "        'Census_IsAlwaysOnAlwaysConnectedCapable', 'Wdft_IsGamer',\n",
    "        'Wdft_RegionIdentifier']\n",
    "\n",
    "# LOAD ALL AS CATEGORIES\n",
    "dtypes = {}\n",
    "for x in FE+OHE: dtypes[x] = 'category'\n",
    "dtypes['MachineIdentifier'] = 'str'\n",
    "dtypes['HasDetections'] = 'int8'\n",
    "\n",
    "# LOAD CSV FILE\n",
    "df_train = pd.read_csv('/home/ryan/cs/datasets/microsoft/train.csv', usecols=dtypes.keys(), dtype=dtypes)\n",
    "print ('Loaded',len(df_train),'rows of TRAIN.CSV!')\n",
    "\n",
    "# DOWNSAMPLE\n",
    "# sm = 2000000\n",
    "# df_train = df_train.sample(sm)\n",
    "# print ('Only using',sm,'rows to train and validate')\n",
    "x=gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# CHECK FOR NAN\n",
    "def nan_check(x):\n",
    "    if isinstance(x,float):\n",
    "        if math.isnan(x):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# FREQUENCY ENCODING\n",
    "def encode_FE(df,col,verbose=1):\n",
    "    d = df[col].value_counts(dropna=False)\n",
    "    n = col+\"_FE\"\n",
    "    df[n] = df[col].map(d)/d.max()\n",
    "    if verbose==1:\n",
    "        print('FE encoded',col)\n",
    "    return [n]\n",
    "\n",
    "# ONE-HOT-ENCODE ALL CATEGORY VALUES THAT COMPRISE MORE THAN\n",
    "# \"FILTER\" PERCENT OF TOTAL DATA AND HAS SIGNIFICANCE GREATER THAN \"ZVALUE\"\n",
    "def encode_OHE(df, col, filter, zvalue, tar='HasDetections', m=0.5, verbose=1):\n",
    "    cv = df[col].value_counts(dropna=False)\n",
    "    cvd = cv.to_dict()\n",
    "    vals = len(cv)\n",
    "    th = filter * len(df)\n",
    "    sd = zvalue * 0.5/ math.sqrt(th)\n",
    "    #print(sd)\n",
    "    n = []; ct = 0; d = {}\n",
    "    for x in cv.index:\n",
    "        try:\n",
    "            if cv[x]<th: break\n",
    "            sd = zvalue * 0.5/ math.sqrt(cv[x])\n",
    "        except:\n",
    "            if cvd[x]<th: break\n",
    "            sd = zvalue * 0.5/ math.sqrt(cvd[x])\n",
    "        if nan_check(x): r = df[df[col].isna()][tar].mean()\n",
    "        else: r = df[df[col]==x][tar].mean()\n",
    "        if abs(r-m)>sd:\n",
    "            nm = col+'_BE_'+str(x)\n",
    "            if nan_check(x): df[nm] = (df[col].isna()).astype('int8')\n",
    "            else: df[nm] = (df[col]==x).astype('int8')\n",
    "            n.append(nm)\n",
    "            d[x] = 1\n",
    "        ct += 1\n",
    "        if (ct+1)>=vals: break\n",
    "    if verbose==1:\n",
    "        print('OHE encoded',col,'- Created',len(d),'booleans')\n",
    "    return [n,d]\n",
    "\n",
    "# ONE-HOT-ENCODING from dictionary\n",
    "def encode_OHE_test(df,col,dt):\n",
    "    n = []\n",
    "    for x in dt: \n",
    "        n += encode_BE(df,col,x)\n",
    "    return n\n",
    "\n",
    "# BOOLEAN ENCODING\n",
    "def encode_BE(df,col,val):\n",
    "    n = col+\"_BE_\"+str(val)\n",
    "    if nan_check(val):\n",
    "        df[n] = df[col].isna()\n",
    "    else:\n",
    "        df[n] = df[col]==val\n",
    "    df[n] = df[n].astype('int8')\n",
    "    return [n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FE encoded EngineVersion\n",
      "FE encoded AppVersion\n",
      "FE encoded AvSigVersion\n",
      "FE encoded Census_OSVersion\n",
      "OHE encoded RtpStateBitfield - Created 2 booleans\n",
      "OHE encoded IsSxsPassiveMode - Created 1 booleans\n",
      "OHE encoded DefaultBrowsersIdentifier - Created 2 booleans\n",
      "OHE encoded AVProductStatesIdentifier - Created 11 booleans\n",
      "OHE encoded AVProductsInstalled - Created 3 booleans\n",
      "OHE encoded AVProductsEnabled - Created 2 booleans\n",
      "OHE encoded CountryIdentifier - Created 47 booleans\n",
      "OHE encoded CityIdentifier - Created 13 booleans\n",
      "OHE encoded GeoNameIdentifier - Created 38 booleans\n",
      "OHE encoded LocaleEnglishNameIdentifier - Created 31 booleans\n",
      "OHE encoded Processor - Created 2 booleans\n",
      "OHE encoded OsBuild - Created 8 booleans\n",
      "OHE encoded OsSuite - Created 2 booleans\n",
      "OHE encoded SmartScreen - Created 5 booleans\n",
      "OHE encoded Census_MDC2FormFactor - Created 6 booleans\n",
      "OHE encoded Census_OEMNameIdentifier - Created 20 booleans\n",
      "OHE encoded Census_ProcessorCoreCount - Created 6 booleans\n",
      "OHE encoded Census_ProcessorModelIdentifier - Created 34 booleans\n",
      "OHE encoded Census_PrimaryDiskTotalCapacity - Created 16 booleans\n",
      "OHE encoded Census_PrimaryDiskTypeName - Created 4 booleans\n",
      "OHE encoded Census_HasOpticalDiskDrive - Created 1 booleans\n",
      "OHE encoded Census_TotalPhysicalRAM - Created 10 booleans\n",
      "OHE encoded Census_ChassisTypeName - Created 10 booleans\n",
      "OHE encoded Census_InternalPrimaryDiagonalDisplaySizeInInches - Created 25 booleans\n",
      "OHE encoded Census_InternalPrimaryDisplayResolutionHorizontal - Created 7 booleans\n",
      "OHE encoded Census_InternalPrimaryDisplayResolutionVertical - Created 7 booleans\n",
      "OHE encoded Census_PowerPlatformRoleName - Created 4 booleans\n",
      "OHE encoded Census_InternalBatteryType - Created 5 booleans\n",
      "OHE encoded Census_InternalBatteryNumberOfCharges - Created 4 booleans\n",
      "OHE encoded Census_OSEdition - Created 4 booleans\n",
      "OHE encoded Census_OSInstallLanguageIdentifier - Created 22 booleans\n",
      "OHE encoded Census_GenuineStateName - Created 2 booleans\n",
      "OHE encoded Census_ActivationChannel - Created 4 booleans\n",
      "OHE encoded Census_FirmwareManufacturerIdentifier - Created 17 booleans\n",
      "OHE encoded Census_IsTouchEnabled - Created 1 booleans\n",
      "OHE encoded Census_IsPenCapable - Created 1 booleans\n",
      "OHE encoded Census_IsAlwaysOnAlwaysConnectedCapable - Created 2 booleans\n",
      "OHE encoded Wdft_IsGamer - Created 2 booleans\n",
      "OHE encoded Wdft_RegionIdentifier - Created 14 booleans\n",
      "Encoded 399 new variables\n",
      "Removed original 43 variables\n"
     ]
    }
   ],
   "source": [
    "cols = []; dd = []\n",
    "\n",
    "# ENCODE NEW\n",
    "for x in FE:\n",
    "    cols += encode_FE(df_train,x)\n",
    "for x in OHE:\n",
    "    tmp = encode_OHE(df_train,x,0.005,5)\n",
    "    cols += tmp[0]; dd.append(tmp[1])\n",
    "print('Encoded',len(cols),'new variables')\n",
    "\n",
    "# REMOVE OLD\n",
    "for x in FE+OHE:\n",
    "    del df_train[x]\n",
    "print('Removed original',len(FE+OHE),'variables')\n",
    "x = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class printAUC(callbacks.Callback):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        super(printAUC, self).__init__()\n",
    "        self.bestAUC = 0\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        pred = self.model.predict(np.array(self.X_train))\n",
    "        auc = roc_auc_score(self.y_train, pred)\n",
    "        print(\"Train AUC: \" + str(auc))\n",
    "        pred = self.model.predict(self.validation_data[0])\n",
    "        auc = roc_auc_score(self.validation_data[1], pred)\n",
    "        print (\"Validation AUC: \" + str(auc))\n",
    "        if (self.bestAUC < auc) :\n",
    "            self.bestAUC = auc\n",
    "            self.model.save(\"bestNet.h5\", overwrite=True)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7137186 samples, validate on 1784297 samples\n",
      "Epoch 1/20\n",
      " - 732s - loss: 0.6374 - acc: 0.6294 - val_loss: 0.6285 - val_acc: 0.6408\n",
      "Train AUC: 0.703032087699\n",
      "Validation AUC: 0.702713621318\n",
      "Epoch 2/20\n",
      " - 871s - loss: 0.6335 - acc: 0.6344 - val_loss: 0.6234 - val_acc: 0.6436\n",
      "Train AUC: 0.705386178323\n",
      "Validation AUC: 0.70495618046\n",
      "Epoch 3/20\n",
      " - 937s - loss: 0.6322 - acc: 0.6358 - val_loss: 0.6285 - val_acc: 0.6438\n",
      "Train AUC: 0.706179512997\n",
      "Validation AUC: 0.705682650344\n",
      "Epoch 4/20\n",
      " - 848s - loss: 0.6315 - acc: 0.6369 - val_loss: 0.6222 - val_acc: 0.6452\n",
      "Train AUC: 0.707216238817\n",
      "Validation AUC: 0.706640123416\n",
      "Epoch 5/20\n",
      " - 760s - loss: 0.6311 - acc: 0.6374 - val_loss: 0.6305 - val_acc: 0.6439\n",
      "Train AUC: 0.707900991174\n",
      "Validation AUC: 0.707251006784\n",
      "Epoch 6/20\n",
      " - 851s - loss: 0.6306 - acc: 0.6380 - val_loss: 0.6202 - val_acc: 0.6461\n",
      "Train AUC: 0.708522917471\n",
      "Validation AUC: 0.707770139604\n",
      "Epoch 7/20\n",
      " - 861s - loss: 0.6302 - acc: 0.6385 - val_loss: 0.6203 - val_acc: 0.6469\n",
      "Train AUC: 0.709101305981\n",
      "Validation AUC: 0.70828528009\n",
      "Epoch 8/20\n",
      " - 779s - loss: 0.6300 - acc: 0.6388 - val_loss: 0.6208 - val_acc: 0.6470\n",
      "Train AUC: 0.709222370636\n",
      "Validation AUC: 0.70838556502\n",
      "Epoch 9/20\n",
      " - 830s - loss: 0.6297 - acc: 0.6391 - val_loss: 0.6202 - val_acc: 0.6467\n",
      "Train AUC: 0.709690831548\n",
      "Validation AUC: 0.708664376297\n",
      "Epoch 10/20\n",
      " - 842s - loss: 0.6294 - acc: 0.6395 - val_loss: 0.6206 - val_acc: 0.6469\n",
      "Train AUC: 0.709876692677\n",
      "Validation AUC: 0.708926116246\n",
      "Epoch 11/20\n",
      " - 800s - loss: 0.6290 - acc: 0.6398 - val_loss: 0.6222 - val_acc: 0.6460\n",
      "Train AUC: 0.710124737213\n",
      "Validation AUC: 0.709232134771\n",
      "Epoch 12/20\n",
      " - 818s - loss: 0.6290 - acc: 0.6400 - val_loss: 0.6209 - val_acc: 0.6448\n",
      "Train AUC: 0.710458179255\n",
      "Validation AUC: 0.70939493421\n",
      "Epoch 13/20\n",
      " - 812s - loss: 0.6288 - acc: 0.6402 - val_loss: 0.6210 - val_acc: 0.6461\n",
      "Train AUC: 0.710708193902\n",
      "Validation AUC: 0.709656832196\n",
      "Epoch 14/20\n",
      " - 768s - loss: 0.6287 - acc: 0.6402 - val_loss: 0.6190 - val_acc: 0.6478\n",
      "Train AUC: 0.710588844135\n",
      "Validation AUC: 0.70946426887\n",
      "Epoch 15/20\n",
      " - 819s - loss: 0.6284 - acc: 0.6405 - val_loss: 0.6223 - val_acc: 0.6468\n",
      "Train AUC: 0.710843834261\n",
      "Validation AUC: 0.709735496591\n",
      "Epoch 16/20\n",
      " - 799s - loss: 0.6282 - acc: 0.6407 - val_loss: 0.6207 - val_acc: 0.6474\n",
      "Train AUC: 0.711008431657\n",
      "Validation AUC: 0.709861663069\n",
      "Epoch 17/20\n",
      " - 765s - loss: 0.6280 - acc: 0.6410 - val_loss: 0.6188 - val_acc: 0.6484\n",
      "Train AUC: 0.71107490089\n",
      "Validation AUC: 0.709926137666\n",
      "Epoch 18/20\n",
      " - 789s - loss: 0.6279 - acc: 0.6411 - val_loss: 0.6186 - val_acc: 0.6480\n",
      "Train AUC: 0.711159241781\n",
      "Validation AUC: 0.709972577376\n",
      "Epoch 19/20\n",
      " - 799s - loss: 0.6278 - acc: 0.6410 - val_loss: 0.6182 - val_acc: 0.6486\n",
      "Train AUC: 0.711296885925\n",
      "Validation AUC: 0.710108179856\n",
      "Epoch 20/20\n",
      " - 758s - loss: 0.6276 - acc: 0.6412 - val_loss: 0.6195 - val_acc: 0.6468\n",
      "Train AUC: 0.711410207203\n",
      "Validation AUC: 0.710190055644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb09f3bd128>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "#SPLIT TRAIN AND VALIDATION SET\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    df_train[cols], df_train['HasDetections'], test_size = 0.2)\n",
    "\n",
    "# BUILD MODEL\n",
    "model = Sequential()\n",
    "model.add(Dense(100,input_dim=len(cols)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(100))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=Adam(lr=0.01), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "annealer = LearningRateScheduler(lambda x: 1e-2 * 0.95 ** x)\n",
    "\n",
    "# TRAIN MODEL\n",
    "model.fit(X_train,Y_train, batch_size=32, epochs = 20, callbacks=[annealer,\n",
    "          printAUC(X_train, Y_train)], validation_data = (X_val,Y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cols = list(dtypes.keys())\n",
    "test_cols.remove('HasDetections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2000000 rows of TEST.CSV!\n",
      "  encoded and predicted part 1\n",
      "Loaded 2000000 rows of TEST.CSV!\n",
      "  encoded and predicted part 2\n",
      "Loaded 2000000 rows of TEST.CSV!\n",
      "  encoded and predicted part 3\n",
      "Loaded 1853253 rows of TEST.CSV!\n",
      "  encoded and predicted part 4\n"
     ]
    }
   ],
   "source": [
    "# del df_train\n",
    "# del X_train, X_val, Y_train, Y_val\n",
    "x = gc.collect()\n",
    "\n",
    "# LOAD BEST SAVED NET\n",
    "from keras.models import load_model\n",
    "model = load_model('bestNet.h5')\n",
    "\n",
    "pred = np.zeros((7853253,1))\n",
    "id = 1\n",
    "chunksize = 2000000\n",
    "for df_test in pd.read_csv('/home/ryan/cs/datasets/microsoft/test.csv', \n",
    "            chunksize = chunksize, usecols=test_cols, dtype=dtypes):\n",
    "    print ('Loaded',len(df_test),'rows of TEST.CSV!')\n",
    "    # ENCODE TEST\n",
    "    cols = []\n",
    "    for x in FE:\n",
    "        cols += encode_FE(df_test,x,verbose=0)\n",
    "    for x in range(len(OHE)):\n",
    "        cols += encode_OHE_test(df_test,OHE[x],dd[x])\n",
    "    # PREDICT TEST\n",
    "    end = (id)*chunksize\n",
    "    if end>7853253: end = 7853253\n",
    "    pred[(id-1)*chunksize:end] = model.predict_proba(df_test[cols])\n",
    "    print('  encoded and predicted part',id)\n",
    "    id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUBMIT TO KAGGLE\n",
    "df_test = pd.read_csv('/home/ryan/cs/datasets/microsoft/test.csv', usecols=['MachineIdentifier'])\n",
    "df_test['HasDetections'] = pred\n",
    "df_test.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
